{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8c9ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "from common.np import *\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import ptb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50362574",
   "metadata": {},
   "source": [
    "# 2.1 単語の意味の表現方法\n",
    "- シソーラス  \n",
    "類語辞書．人の手で単語同士の関連を定義する．\n",
    "\n",
    "\n",
    "- カウントベース  \n",
    "「単語の意味は周囲の単語によって形成される」という分布仮説に基づく．\n",
    "大量のテキストデータを使い，ある単語の周囲の単語をカウントすることで，単語をベクトルで表現する．\n",
    "\n",
    "\n",
    "- 推論ベース  \n",
    "分布仮説に基づく．\n",
    "ある単語の周囲の単語を特徴量として，単語を推測するモデルを使う．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d83a39",
   "metadata": {},
   "source": [
    "# 2.3 カウントベースの手法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2827ce5d",
   "metadata": {},
   "source": [
    "## コーパスの下準備\n",
    "以下の3つを行う preprocess関数を実装\n",
    "- コーパスを単語IDのリストに変換\n",
    "- IDから単語へ変換するためのディクショナリを用意\n",
    "- 単語からIDへ変換するためのディクショナリを用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f0d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \n",
    "    text = text.lower()             # 文字を小文字に変える\n",
    "    text = text.replace('.', ' .')  # ピリオドの前にスペースを入れる\n",
    "    words = text.split(' ')         # スペースで分割してリスト化\n",
    "\n",
    "    word_to_id = {}  # 単語からIDに変換するためのディクショナリ\n",
    "    id_to_word = {}  # IDから単語に変換するためのディクショナリ\n",
    "    \n",
    "    # ディクショナリにない単語の場合，新しいIDとして追加する\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "\n",
    "    # リスト化した単語をIDに変換する\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "\n",
    "    return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb22410",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5914ff91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text      : You say goodbye and I say hello.\n",
      "corpus    : [0 1 2 3 4 1 5 6]\n",
      "word_to_id: {'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
      "id_to_word: {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "print('text      :', text)\n",
    "print('corpus    :', corpus)\n",
    "print('word_to_id:', word_to_id)\n",
    "print('id_to_word:', id_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375c3b17",
   "metadata": {},
   "source": [
    "## 共起行列\n",
    "- 行: 単語を表すベクトル\n",
    "- 列: その単語がwindow内に何度出現したかをカウントした値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4be9234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    '''共起行列の作成\n",
    "\n",
    "    :param corpus: コーパス（単語IDのリスト）\n",
    "    :param vocab_size:語彙数\n",
    "    :param window_size:ウィンドウサイズ（ウィンドウサイズが1のときは、単語の左右1単語がコンテキスト）\n",
    "    :return: 共起行列\n",
    "    '''\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "\n",
    "    # ループを回して，corpusの単語ごとに処理\n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            # コンテキストのインデックスを取得\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "\n",
    "            # 左側のコンテキストがcorpus内であればco_matrixに値を追加\n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "            # 右側のコンテキストがcorpus内であればco_matrixに値を追加\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "\n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a10653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# 共起行列を作る\n",
    "# vocab_sizeは辞書の要素数\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f30b671",
   "metadata": {},
   "source": [
    "## コサイン類似度\n",
    "\n",
    "$$\n",
    "\\mathrm{similarity}(\\boldsymbol{x}, \\boldsymbol{y})\n",
    "= \\frac{\\boldsymbol{x} \\cdot \\boldsymbol{y}}{\\| \\boldsymbol{x} \\| \\| \\boldsymbol{y} \\|}\n",
    "= \\frac{x_1 y_1 + \\cdots + x_n y_n}{\\sqrt{x_1^2 + \\cdots + x_n^2} \\sqrt{y_1^2 + \\cdots + y_n^2}}\n",
    "\\\\\n",
    "\\\\\n",
    "\\boldsymbol{x} \\cdot \\boldsymbol{y} = \\| \\boldsymbol{x} \\| \\| \\boldsymbol{y} \\| \\mathrm{cos \\theta}\n",
    "$$\n",
    "\n",
    "- ベクトルの類似度の指標として使う．\n",
    "- 内積をノルムの積で割るので結局は $\\mathrm{cos} \\theta$．$\\theta$ はベクトル $\\boldsymbol{x}, \\boldsymbol{y}$ の成す角．\n",
    "- 直交するとき $\\mathrm{similarity}(\\boldsymbol{x}, \\boldsymbol{y}) = 0$．\n",
    "- 同じ方向を向くとき $\\mathrm{similarity}(\\boldsymbol{x}, \\boldsymbol{y}) = 1$．\n",
    "- 反対方向を向くとき $\\mathrm{similarity}(\\boldsymbol{x}, \\boldsymbol{y}) = -1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "269c55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y, eps=1e-8):\n",
    "    '''コサイン類似度の算出\n",
    "\n",
    "    :param x: ベクトル\n",
    "    :param y: ベクトル\n",
    "    :param eps: ”0割り”防止のための微小値\n",
    "    :return:\n",
    "    '''\n",
    "    # ノルムを 1 にしてから内積を取る\n",
    "    nx = x / (np.sqrt(np.sum(x ** 2)) + eps)\n",
    "    ny = y / (np.sqrt(np.sum(y ** 2)) + eps)\n",
    "    return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb384f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067691154799\n"
     ]
    }
   ],
   "source": [
    "# you と i のコサイン類似度を求めてみる\n",
    "c0 = C[word_to_id['you']]\n",
    "c1 = C[word_to_id['i']]\n",
    "print(cos_similarity(c0, c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c53a4e",
   "metadata": {},
   "source": [
    "## 類似単語のランキング表示\n",
    "- クエリとして与えられた単語に対して，コサイン類似度の高い単語を上位から表示する関数を実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86a3794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "    '''類似単語の検索\n",
    "\n",
    "    :param query: クエリ（テキスト）\n",
    "    :param word_to_id: 単語から単語IDへのディクショナリ\n",
    "    :param id_to_word: 単語IDから単語へのディクショナリ\n",
    "    :param word_matrix: 単語ベクトルをまとめた行列。各行に対応する単語のベクトルが格納されていることを想定する\n",
    "    :param top: 上位何位まで表示するか\n",
    "    '''\n",
    "    # 辞書に含まれないクエリの場合は処理を実行しない\n",
    "    if query not in word_to_id:\n",
    "        print('%s is not found' % query)\n",
    "        return\n",
    "\n",
    "    # クエリの単語IDとベクトルを取得\n",
    "    print('\\n[query] ' + query)\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "\n",
    "    # 語彙数を取得\n",
    "    vocab_size = len(id_to_word)\n",
    "\n",
    "    # 類似度を保持する配列を生成\n",
    "    # 語彙数と同じ要素数が必要\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    \n",
    "    # 共起行列のベクトルを一つずつ取り出し，クエリの単語とのコサイン類似度を計算\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "\n",
    "    count = 0\n",
    "    # 類似度の降順で処理（argsort()では要素の昇順にインデックスを返す）\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        # クエリと同じ単語IDのときは処理しない\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
    "\n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7e1565e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " goodbye: 0.7071067691154799\n",
      " i: 0.7071067691154799\n",
      " hello: 0.7071067691154799\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "most_similar('you', word_to_id, id_to_word, C, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914fdf8a",
   "metadata": {},
   "source": [
    "### argsort()の挙動  \n",
    "要素の値の昇順にインデックスを並べる  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e41520d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2]\n",
      "[2 0 1]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([10, -5, 20])\n",
    "print(x.argsort())\n",
    "print((-1 * x).argsort())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaa4fae",
   "metadata": {},
   "source": [
    "# 2.4 カウントベースの手法の改善\n",
    "## 相互情報量\n",
    "共起行列の欠点として，\"the\"や\"a\"のような出現頻度が高い単語に強い関連性を持ってしまうことがある  \n",
    "問題解決のため次の**相互情報量(Pointwise Mutual Information)**を使う\n",
    "\n",
    "$$\n",
    "\\mathrm{PMI}(x, y) = \\log_2 \\frac{P(x, y)}{P(x) P(y)}\n",
    "$$\n",
    "\n",
    "- $P(x)$: $x$ が起こる確率\n",
    "- $P(y)$: $y$ が起こる確率\n",
    "- $P(x, y)$: $x, y$ が同時に起こる確率\n",
    "\n",
    "***\n",
    "\n",
    "## 共起行列を使って相互情報量を求める\n",
    "\n",
    "$$\n",
    "\\mathrm{PMI}(x, y) = \\log_2 \\frac{\\frac{C(x, y)}{N}}{\\frac{C(x)}{N} \\frac{C(y)}{N}} = \\log_2 \\frac{C(x, y) \\cdot N}{C(x) C(y)}\n",
    "$$\n",
    "\n",
    "- $C(x)$: $x$ がコーパスに出現する回数\n",
    "- $C(y)$: $y$ がコーパスに出現する回数\n",
    "- $C(x, y)$: $x, y$ の共起する回数\n",
    "- $N$: コーパスに含まれる単語数\n",
    "\n",
    "***\n",
    "\n",
    "## 使ってみる\n",
    "次の仮定では共起回数の観点で\"car\"は\"drive\"よりも\"the\"の方に関連が強い\n",
    "- コーパスの単語数 $N = 10000$\n",
    "- \"the\"の出現回数 $C(\\mathrm{\"the\"}) = 100$\n",
    "- \"car\"の出現回数 $C(\\mathrm{\"car\"}) = 20$\n",
    "- \"drive\"の出現回数 $C(\\mathrm{\"the\"}) = 10$\n",
    "- \"the\"と\"car\"の共起回数 $C(\\mathrm{\"the\"}, \\mathrm{\"car\"}) = 10$\n",
    "- \"car\"と\"drive\"の共起回数 $C(\\mathrm{\"car\"}, \\mathrm{\"drive\"}) = 5$\n",
    "\n",
    "<br/>\n",
    "\n",
    "PMIを使うと\"drive\"の方に関連が強いことになる\n",
    "$$\n",
    "\\mathrm{PMI}(\\mathrm{\"the\"}, \\mathrm{\"car\"}) = \\log_2 \\frac{10 \\cdot 10000}{100 \\cdot 20} \\approx 5.64\n",
    "\\\\[10pt]\n",
    "\\mathrm{PMI}(\\mathrm{\"car\"}, \\mathrm{\"drive\"}) = \\log_2 \\frac{5 \\cdot 10000}{20 \\cdot 10} \\approx 7.97\n",
    "$$\n",
    "\n",
    "<br/>\n",
    "\n",
    "実装では，$\\log_2 0 = - \\infty$ を防ぐために $\\mathrm{PPMI}(x, y) = \\mathrm{max}(0, \\mathrm{PMI}(x, y))$ を使う．PMIが負になるときは0として扱う．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fe348da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(C, verbose=False, eps = 1e-8):\n",
    "    '''PPMI（正の相互情報量）の作成\n",
    "\n",
    "    :param C: 共起行列\n",
    "    :param verbose: 進行状況を出力するかどうか\n",
    "    :return: PPMI行列\n",
    "    '''\n",
    "    M = np.zeros_like(C, dtype=np.float32)  # 共起行列と同じ形状の配列\n",
    "    N = np.sum(C)  # コーパスの単語数の代わり\n",
    "    S = np.sum(C, axis=0)  # 各単語の出現回数の代わり\n",
    "    \n",
    "    # 進行状況確認用の変数\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[j]*S[i]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "\n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100 + 1) == 0:\n",
    "                    print('%.1f%% done' % (100*cnt/total))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b19a715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = ppmi(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "710b65f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance matrix\n",
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "--------------------------------------------------\n",
      "PPMI\n",
      "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.807 0.    0.    0.    0.    2.807]\n",
      " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "print('covariance matrix')\n",
    "print(C)\n",
    "print('-'*50)\n",
    "print('PPMI')\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebdf735",
   "metadata": {},
   "source": [
    "## 次元削減\n",
    "PPMI行列は共起行列より良い指標の行列となったが，語彙数の増加に伴いベクトルの次元数が膨大になるという問題が残っている．\n",
    "また要素の多くが0である「疎なベクトル」であり，ノイズに弱く，頑健性に乏しい．これらの問題の対策として次元削減を行う．  \n",
    "今回は特異値分解（SVD）を行う．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "819f4a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, V = np.linalg.svd(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28a31acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(C)  # 共起行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "559fabee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.807 0.    0.    0.    0.    2.807]\n",
      " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(W)  # PPMI行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26fbd4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.409e-01 -1.110e-16 -1.205e-01 -4.163e-16 -9.323e-01 -1.110e-16\n",
      "  -2.426e-17]\n",
      " [ 0.000e+00 -5.976e-01  0.000e+00  1.802e-01  0.000e+00 -7.812e-01\n",
      "   0.000e+00]\n",
      " [ 4.363e-01 -5.551e-17 -5.088e-01 -2.220e-16  2.253e-01 -1.388e-17\n",
      "  -7.071e-01]\n",
      " [ 1.665e-16 -4.978e-01  2.776e-17  6.804e-01 -1.110e-16  5.378e-01\n",
      "   7.467e-17]\n",
      " [ 4.363e-01 -3.124e-17 -5.088e-01 -1.600e-16  2.253e-01 -1.302e-17\n",
      "   7.071e-01]\n",
      " [ 7.092e-01 -3.124e-17  6.839e-01 -1.600e-16  1.710e-01 -1.302e-17\n",
      "   2.314e-17]\n",
      " [-1.665e-16 -6.285e-01 -4.163e-17 -7.103e-01  2.220e-16  3.169e-01\n",
      "  -9.614e-17]]\n"
     ]
    }
   ],
   "source": [
    "print(U)  # SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bbd56c",
   "metadata": {},
   "source": [
    "例として，2次元に削減すると"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "573f5f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.409e-01 -1.110e-16]\n",
      " [ 0.000e+00 -5.976e-01]\n",
      " [ 4.363e-01 -5.551e-17]\n",
      " [ 1.665e-16 -4.978e-01]\n",
      " [ 4.363e-01 -3.124e-17]\n",
      " [ 7.092e-01 -3.124e-17]\n",
      " [-1.665e-16 -6.285e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(U[:, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a4ddd",
   "metadata": {},
   "source": [
    "2次元でプロットする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b88517b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAahElEQVR4nO3dfXRU9b3v8feXJJT4wARRIGIR21KlBiIkKNQW68FAinqAWlsfLuIDpqK4tOscq10s+6D2XNtyj4Vez/FGDxBbbuEoPh0VLoh6EMUK0YBBrNGq5SENFCUWDAjke//I8DOmk2TCZmaS9PNaK2v2nvnt/fuwGfLJ3jNDzN0REREB6JHpACIi0nmoFEREJFApiIhIoFIQEZFApSAiIkF2pgO05fjjj/fBgwdnOoaISJdRWVn5F3c/4XC379SlMHjwYNatW5fpGCIiXYaZvR9le10+EhGRQKUg0g189atfPeL7fO+99ygoKABgwYIFzJw584jPIa1rfvyT8ZOf/ITZs2cDYGYLzOzbhzOvSkGkG3jppZcyHUG6CZWCSBtuv/125syZE9ZnzZrFnDlzuOWWWygoKGDYsGEsXrwYgOeff54LLrggjJ05cyYLFixIS85jjjmGO++8k9NOO42SkhIuvfRSZs+eTVVVFaNHj2b48OFMmTKFDz/8EKDV+ysrKyksLGTMmDHce++9n5lj8+bNlJaWcuqpp/LTn/4USHx85s6dC8Avf/lLRo0axfDhw/nxj3+cjsPQ7Rw8eJBrr72W008/nfHjx9PQ0MA777xDaWkpRUVFfP3rX+fNN99scx9mNs7MXjOz181snpl9rq3xKgWRNlxzzTVUVFQA0NjYyKJFizjppJOoqqpi/fr1PPPMM9xyyy3U1tZmNGdjYyNLlizhtdde45FHHglv0Ljiiiv4+c9/zoYNGxg2bFj4Zt7a/VdddRVz585lzZo1fzPHK6+8wsKFC6mqquKhhx5i3bp1CY/P5ZdfzvLly6mpqeGVV16hqqqKyspKVq1alaaj0X3U1NRwww03sHHjRvLy8liyZAllZWX8+te/prKyktmzZ3P99de3ur2Z9QIWAN9192E0vbloRltzHpF3H5lZKTAHyAIecPe7Wzxu8ccnAh8DV7r7q0dibpFU2FRbz7LqOrbuamAPuSxZvoqjGz9mxIgRrF69mksvvZSsrCz69+/POeecw9q1a+ndu3daMz61YSsVa/5E3Ud72ffJAb4y+lxyc3MBuPDCC9mzZw+7du3inHPOAWDatGlcfPHF1NfXJ3X/1KlTWbp0aZivpKSEvn37AvCtb32L1atXc/PNN9O3b19ee+016urqGDFiBH379mX58uUsX76cESNGALB7925qamoYO3Zs2o5PV9T8eZe7dycDB53MGWecAUBRURHvvfceL730EhdffHHYZt++fW3t8lTgXXd/K75eAdwA/Kq1DSKXgpllAfcCJcAWYK2ZPeHubzQb9k1gSPzrLODf47cinc6m2nrKV71LLDeH/Fgvho2bwl333MeAnL3ceN10li9fnnC77OxsGhsbw/revXtTlvGpDVu5e+kfOPpz2fQ7pieOs/rtnTy1YSvnDx94WPt0d5p+fkus5WOH1qdPn86CBQv485//zNVXXx329cMf/pDvfe97h5Xl71HL593mXQfYs9/YVFvP0PwYWVlZ1NXVkZeXR1VVVbK7bf0vtBVH4vLRmcDb7v5Hd/8EWARMajFmEvCgN3kZyDOz/CMwt8gRt6y6jlhuDrHcHHqYcda5pWzesIZX1q5lwoQJjB07lsWLF3Pw4EF27NjBqlWrOPPMMzn55JN544032LdvH/X19axcuTJlGSvW/ImjP5fdlLFHD3r0yGLXmy8zb1UNu3fv5qmnnuLoo4+mT58+vPDCCwD85je/4ZxzziEWiyW8Py8vj1gsxurVqwFYuHDhZ+ZcsWIFH3zwAQ0NDTz22GOcffbZAEyZMoVly5axNn58ACZMmMC8efPYvXs3AFu3bmX79u0pOx7dQcvn3bG9sunRw1hWXRfG9O7dm1NOOYWHHnoIaCrf9evXt7XbN4HBZval+PpU4L/b2uBIXD4aCGxutr6Fvz0LSDRmIPA3F2LNrAwoAxg0aNARiCfSMVt3NZAf6xXWs3N6MuSMsziYcxRZWVlMmTKFNWvWUFhYiJnxi1/8ggEDBgDwne98h+HDhzNkyJBw6SQV6j7aS79jeoZ169GDkwq/xtKfTuVbTwyluLiYWCxGRUUF1113HR9//DFf+MIXmD9/PkCr98+fP5+rr76ao446KnyDP+RrX/saU6dO5e233+ayyy6juLgYgJ49e3LuueeSl5dHVlYWAOPHj2fTpk2MGTMGaHoh/Le//S39+vVL2THp6lo+7wB6mLF1V8Nn7lu4cCEzZszgrrvuYv/+/VxyySUUFhYm3Ke77zWzq4CHzCwbWAvc11YOi/pLdszsYmCCu0+Pr08FznT3G5uNeQr4n+6+Or6+EviBu1e2te/i4mLXJ5ol3e5Z8Rb1DfuJ5eYATS+g/nLGZK7+0Vz+5crxGU7X5Dv/Zw0fNcsIsHNXPcflxVgwtZCxY8dSXl7OyJEjU56lsbGRkSNH8tBDDzFkyJCUz9ddtXzeAWH9+yVfTno/Zlbp7sWHm+NIXD7aAny+2fpJwLbDGCPSKZQW9Ke+YT/1DfvZ9l4Nd00rYeBXRjF1Qud5GWzamEHs2XeA+ob9NDY2Ut+wnw2/+yXr7pnOyJEjueiii9JSCG+88QZf+tKXGDdunAohoubPu0b3sFxa0D+tOY7EmUI28BYwDthK0+nJZe6+sdmY84GZNL376Cxgrruf2d6+daYgmdL8XSAD83IpLejP0PxYpmN9RvN3H/Xv3YtpYwYd9ovM0jkciedd1DOFyKUQDzGRprc4ZQHz3P1nZnYdgLvfF39L6v8GSml6S+pV7t7ud3uVgohIx0QthSPyOQV3fxp4usV99zVbdpreGysiIp2YPtEsIiKBSkFERAKVgoiIBCoFEREJVAoiIhKoFEREJFApiIhIoFIQEZFApSAiIoFKQUREApWCiIgEKgUREQlUCiIiEqgUREQkUCmIiEigUhARkUClICIigUpBREQClYKIiAQqBRERCVQKIiISqBRERCRQKYiISBCpFMzsODNbYWY18ds+rYybZ2bbzaw6ynwiIpJaUc8UbgNWuvsQYGV8PZEFQGnEuUREJMWilsIkoCK+XAFMTjTI3VcBH0ScS0REUixqKfR391qA+G2/qIHMrMzM1pnZuh07dkTdnYiIdEB2ewPM7BlgQIKHZh35OODu5UA5QHFxsadiDhERSazdUnD381p7zMzqzCzf3WvNLB/YfkTTiYhIWkW9fPQEMC2+PA14POL+REQkg6KWwt1AiZnVACXxdczsRDN7+tAgM/sdsAY41cy2mNk1EecVEZEUaPfyUVvcfScwLsH924CJzdYvjTKPiIikhz7RLCIigUpBREQClYKIiAQqBRERCVQKIiISqBRERCRQKYiISKBSEBGRQKUgIiKBSkFERAKVgoiIBCoFEREJVAoiIhKoFEREJFApiIhIoFIQEZFApSAiIoFKQUREApWCiIgEKgUREQlUCiIiEqgUREQkiFQKZnacma0ws5r4bZ8EYz5vZs+Z2SYz22hmN0WZU0REUifqmcJtwEp3HwKsjK+3dAD4J3cfCowGbjCzr0ScV0REUiBqKUwCKuLLFcDklgPcvdbdX40v/xXYBAyMOK+IiKRA1FLo7+610PTNH+jX1mAzGwyMAH7fxpgyM1tnZut27NgRMZ6IiHREdnsDzOwZYECCh2Z1ZCIzOwZYAtzs7h+1Ns7dy4FygOLiYu/IHCIiEk27peDu57X2mJnVmVm+u9eaWT6wvZVxOTQVwkJ3f+Sw04qISEpFvXz0BDAtvjwNeLzlADMz4D+ATe7+rxHnExGRFIpaCncDJWZWA5TE1zGzE83s6fiYs4GpwD+YWVX8a2LEeUVEJAXavXzUFnffCYxLcP82YGJ8eTVgUeYREZH00CeaRUQkUCmIiEigUhARkUClICIigUpBREQClYKIiAQqBRERCVQKIiISqBRERCRQKYiISKBSEBGRQKUgIiKBSkFERAKVgoiIBCoFEREJVAoiIhKoFEREJFApiIhIoFIQEZFApSAiIoFKQUREApWCiIgEkUrBzI4zsxVmVhO/7ZNgTC8ze8XM1pvZRjP7aZQ5RUQkdaKeKdwGrHT3IcDK+HpL+4B/cPdC4Ayg1MxGR5xXRERSIGopTAIq4ssVwOSWA7zJ7vhqTvzLI84rIiIpELUU+rt7LUD8tl+iQWaWZWZVwHZghbv/PuK8IiKSAtntDTCzZ4ABCR6alewk7n4QOMPM8oBHzazA3atbma8MKAMYNGhQslOIiMgR0G4puPt5rT1mZnVmlu/utWaWT9OZQFv72mVmzwOlQMJScPdyoByguLhYl5lERNIo6uWjJ4Bp8eVpwOMtB5jZCfEzBMwsFzgPeDPivCIikgJRS+FuoMTMaoCS+DpmdqKZPR0fkw88Z2YbgLU0vabwZMR5RUQkBdq9fNQWd98JjEtw/zZgYnx5AzAiyjwiIpIe+kSziIgEKgUREQlUCiIiEqgUREQkUCmIiEigUhARkUClICIigUpBREQClYKIiAQqBRERCVQKIiISqBRERCRQKYiISKBSEBGRQKUgIiKBSkFERAKVgoiIBCoFEREJVAoiIhKoFEREJFApiIhIoFIQEZFApSAiIkGkUjCz48xshZnVxG/7tDE2y8xeM7Mno8wpIiKpE/VM4TZgpbsPAVbG11tzE7Ap4nwiIpJCUUthElARX64AJicaZGYnAecDD0ScT0REUihqKfR391qA+G2/Vsb9CvgB0NjeDs2szMzWmdm6HTt2RIwnIiIdkd3eADN7BhiQ4KFZyUxgZhcA29290sy+0d54dy8HygGKi4s9mTlEROTIaLcU3P281h4zszozy3f3WjPLB7YnGHY28I9mNhHoBfQ2s9+6+/847NQiIpISUS8fPQFMiy9PAx5vOcDdf+juJ7n7YOAS4FkVgohI5xS1FO4GSsysBiiJr2NmJ5rZ01HDiYhIerV7+agt7r4TGJfg/m3AxAT3Pw88H2VOERFJHX2iWUREApWCiIgEKgUREQlUCiIiEqgUREQkUCmIiEigUhARkUClICIigUpBREQClYKIiAQqBRERCVQKIiISqBRERCRQKYiISKBSEBGRQKUgIiKBSkFERAKVgoiIBCqFVhxzzDGZjiAiknYqBRERCbp1KUyePJmioiJOP/10ysvLgaYzgFmzZlFYWMjo0aOpq6sD4N1332XMmDGMGjWK22+/PZOxRUQypluXwrx586isrGTdunXMnTuXnTt3smfPHkaPHs369esZO3Ys999/PwA33XQTM2bMYO3atQwYMCDDyUVEMiM7ysZmdhywGBgMvAd8x90/TDDuPeCvwEHggLsXR5m3LZtq61lWXcfWXQ28/sQDvP/qc3wuO4vNmzdTU1NDz549ueCCCwAoKipixYoVALz44ossWbIEgKlTp3LrrbemKqKISKcV9UzhNmCluw8BVsbXW3Ouu5+R6kIoX/Uu9Q372fPeejZVvsh5t97PomWrGDFiBHv37iUnJwczAyArK4sDBw6E7Q/dLyLy9ypqKUwCKuLLFcDkiPuLZFl1HbHcHGK5OXzy8W6O7Z3H8Xm9qXj6JV5++eU2tz377LNZtGgRAAsXLkxHXBGRTidqKfR391qA+G2/VsY5sNzMKs2sLOKcrdq6q4FjezVdETuteCyNBw9QfvO3ePSBf2X06NFtbjtnzhzuvfdeRo0aRX19faoiioh0aububQ8wewZI9MrrLKDC3fOajf3Q3fsk2MeJ7r7NzPoBK4Ab3X1VK/OVAWUAgwYNKnr//feT/bNwz4q3qG/YTyw3J9x3aP37JV9Oej8iIl2VmVVGuUzf7pmCu5/n7gUJvh4H6swsPx4kH9jeyj62xW+3A48CZ7YxX7m7F7t78QknnNChP0xpQX/qG/ZT37CfRvewXFrQv0P7ERH5exX18tETwLT48jTg8ZYDzOxoMzv20DIwHqiOOG9CQ/NjlI09hVhuDrX1e4nl5lA29hSG5sdSMZ2ISLcT6S2pwN3Af5rZNcCfgIuh6XIR8IC7TwT6A4/G39mTDfxfd18Wcd5WDc2PqQRERA5TpFJw953AuAT3bwMmxpf/CBRGmUdERNKjW3+iWUREOkalICIigUpBREQClYKIiAQqBRERCVQKIiISqBRERCRQKYiISKBSEBGRQKUgIiKBSkFERAKVgoiIBCoFEREJVAoiIhKoFEREJFApiIhIoFIQEZFApSAiIoFKQUREApWCiIgE3bYU9uzZw/nnn09hYSEFBQUsXryYO+64g1GjRlFQUEBZWRnuzjvvvMPIkSPDdjU1NRQVFWUwuYhI5nTbUli2bBknnngi69evp7q6mtLSUmbOnMnatWuprq6moaGBJ598ki9+8YvEYjGqqqoAmD9/PldeeWVGs4uIZEq3K4VNtfXcs+ItntqSwyP/tZTpN9zMCy+8QCwW47nnnuOss85i2LBhPPvss2zcuBGA6dOnM3/+fA4ePMjixYu57LLLMvynEBHJjEilYGbHmdkKM6uJ3/ZpZVyemT1sZm+a2SYzGxNl3tZsqq2nfNW71Dfs5/ShpzL9f/0nW+wEbv6nH3DHHXdw/fXX8/DDD/P6669z7bXXsnfvXgAuuugili5dypNPPklRURF9+/ZNRTwRkU4v6pnCbcBKdx8CrIyvJzIHWObupwGFwKaI8ya0rLqOWG4Osdwc/vrBdvrmHcvo8ZMpnDiVV199FYDjjz+e3bt38/DDD4ftevXqxYQJE5gxYwZXXXVVKqKJiHQJ2RG3nwR8I75cATwP3Np8gJn1BsYCVwK4+yfAJxHnTWjrrgbyY70AqH33Lf7r/l9g1oOD1oMnF1Xw2GOPMWzYMAYPHsyoUaM+s+3ll1/OI488wvjx41MRTUSkSzB3P/yNzXa5e16z9Q/dvU+LMWcA5cAbNJ0lVAI3ufueVvZZBpQBDBo0qOj9999POs89K96ivmE/sdyccN+h9e+XfLnNbWfPnk19fT133nln0vOJiHQ2Zlbp7sWHu327l4/M7Bkzq07wNSnJObKBkcC/u/sIYA+tX2bC3cvdvdjdi0844YQkp2hSWtCf+ob91Dfsp9E9LJcW9G9zuylTpvDggw9y0003dWg+EZHupt3LR+5+XmuPmVmdmeW7e62Z5QPbEwzbAmxx99/H1x+mjVKIYmh+jLKxp7Csuo6tuxoYmJfLd0edxND8WJvbPfroo6mIIyLS5UR9TeEJYBpwd/z28ZYD3P3PZrbZzE519z8A42i6lJQSQ/Nj7ZaAiIgkFvXdR3cDJWZWA5TE1zGzE83s6WbjbgQWmtkG4AzgXyLOKyIiKRDpTMHdd9L0k3/L+7cBE5utVwGH/cKHiIikR9TLR53Optr6z7ymUFrQX5eTRESS1K3+m4vmn2jOj/WivmE/5aveZVNtfaajiYh0Cd2qFJp/ormHWVheVl2X6WgiIl1CtyqFrbsaOLbXp1fEymddS+OenWzd1ZDBVCIiXUe3KoWBebn8de+BsF72s/vpcXRfBublZjCViEjX0a1K4XA/0SwiIk26VSkc+kRzLDeH2vq9xHJzKBt7it59JCKSpG73llR9ollE5PB1qzMFERGJRqUgIiKBSkFERAKVgoiIBCoFEREJIv06zlQzsx1A8r+P87OOB/5yBOOkkrKmRlfJ2lVygrKmypHMerK7d+zXVjbTqUshCjNbF+X3lKaTsqZGV8naVXKCsqZKZ8qqy0ciIhKoFEREJOjOpVCe6QAdoKyp0VWydpWcoKyp0mmydtvXFEREpOO685mCiIh0kEpBRESCLl0KZlZqZn8ws7fN7LYEj5uZzY0/vsHMRmYiZzxLe1lPM7M1ZrbPzP45ExmbZWkv6+Xx47nBzF4ys8JM5IxnaS/rpHjOKjNbZ2Zfy0TOeJY2szYbN8rMDprZt9OZr0WG9o7rN8ysPn5cq8zsR5nIGc/S7nGN560ys41m9t/pztgsR3vH9ZZmx7Q6/jw4Lq0h3b1LfgFZwDvAF4CewHrgKy3GTASWAgaMBn7fibP2A0YBPwP+uZMf168CfeLL3+zkx/UYPn3tbDjwZmfN2mzcs8DTwLc7a1bgG8CTmch3GFnzgDeAQfH1fp01a4vxFwLPpjtnVz5TOBN4293/6O6fAIuASS3GTAIe9CYvA3lmlp/uoCSR1d23u/taYH8G8jWXTNaX3P3D+OrLwElpznhIMll3e/xfGHA0kKl3ViTzfAW4EVgCbE9nuBaSzdoZJJP1MuARd/8TNP1bS3PGQzp6XC8FfpeWZM105VIYCGxutr4lfl9Hx6RDZ8mRjI5mvYams7FMSCqrmU0xszeBp4Cr05StpXazmtlAYApwXxpzJZLsc2CMma03s6Vmdnp6ov2NZLJ+GehjZs+bWaWZXZG2dJ+V9L8tMzsKKKXpB4S06sq/ec0S3Nfyp8BkxqRDZ8mRjKSzmtm5NJVCpq7TJ5XV3R8FHjWzscCdwHmpDpZAMll/Bdzq7gfNEg1Pm2SyvkrT/7Gz28wmAo8BQ1IdLIFksmYDRcA4IBdYY2Yvu/tbqQ7XQke+D1wIvOjuH6QwT0JduRS2AJ9vtn4SsO0wxqRDZ8mRjKSymtlw4AHgm+6+M03ZWurQcXX3VWb2RTM73t3T/R+lJZO1GFgUL4TjgYlmdsDdH0tLwk+1m9XdP2q2/LSZ/VsnPq5bgL+4+x5gj5mtAgqBdJdCR56vl5CBS0dAl36hORv4I3AKn75oc3qLMefz2ReaX+msWZuN/QmZfaE5meM6CHgb+GoXeA58iU9faB4JbD203tmythi/gMy90JzMcR3Q7LieCfypsx5XYCiwMj72KKAaKOiMWePjYsAHwNGZ+PvvsmcK7n7AzGYC/4+mV/XnuftGM7su/vh9NL2DYyJN38A+Bq7qrFnNbACwDugNNJrZzTS9M+Gj1vabqazAj4C+wL/Ff6o94Bn4Hx6TzHoRcIWZ7QcagO96/F9eJ8zaKSSZ9dvADDM7QNNxvaSzHld332Rmy4ANQCPwgLtXd8as8aFTgOXedGaTdvpvLkREJOjK7z4SEZEjTKUgIiKBSkFERAKVgoiIBCoFEREJVAoiIhKoFEREJPj/pS6ec6NwugQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for word, word_id in word_to_id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
    "    \n",
    "plt.scatter(U[:, 0], U[:, 1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56732bd",
   "metadata": {},
   "source": [
    "## PTBデータセット (Penn Treebank) での評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44b5afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, word_to_id, id_to_word = ptb.load_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "288956d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus size:  929589\n",
      "corpus[:30] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "id_to_word[0]: aer\n",
      "id_to_word[1]: banknote\n",
      "id_to_word[2]: berlitz\n",
      "\n",
      "word_to_id['car']: 3856\n",
      "word_to_id['happy']: 4428\n",
      "word_to_id['lexus']: 7426\n"
     ]
    }
   ],
   "source": [
    "print('corpus size: ', len(corpus))\n",
    "print('corpus[:30]', corpus[:30])\n",
    "print()\n",
    "print('id_to_word[0]:', id_to_word[0])\n",
    "print('id_to_word[1]:', id_to_word[1])\n",
    "print('id_to_word[2]:', id_to_word[2])\n",
    "print()\n",
    "print(\"word_to_id['car']:\", word_to_id['car'])\n",
    "print(\"word_to_id['happy']:\", word_to_id['happy'])\n",
    "print(\"word_to_id['lexus']:\", word_to_id['lexus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d4d567",
   "metadata": {},
   "source": [
    "#### まとめて実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02c9b702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting co-occurrence ...\n",
      "calculating PPMI ...\n",
      "1.0% done\n",
      "2.0% done\n",
      "3.0% done\n",
      "4.0% done\n",
      "5.0% done\n",
      "6.0% done\n",
      "7.0% done\n",
      "8.0% done\n",
      "9.0% done\n",
      "10.0% done\n",
      "11.0% done\n",
      "12.0% done\n",
      "13.0% done\n",
      "14.0% done\n",
      "15.0% done\n",
      "16.0% done\n",
      "17.0% done\n",
      "18.0% done\n",
      "19.0% done\n",
      "20.0% done\n",
      "21.0% done\n",
      "22.0% done\n",
      "23.0% done\n",
      "24.0% done\n",
      "25.0% done\n",
      "26.0% done\n",
      "27.0% done\n",
      "28.0% done\n",
      "29.0% done\n",
      "30.0% done\n",
      "31.0% done\n",
      "32.0% done\n",
      "33.0% done\n",
      "34.0% done\n",
      "35.0% done\n",
      "36.0% done\n",
      "37.0% done\n",
      "38.0% done\n",
      "39.0% done\n",
      "40.0% done\n",
      "41.0% done\n",
      "42.0% done\n",
      "43.0% done\n",
      "44.0% done\n",
      "45.0% done\n",
      "46.0% done\n",
      "47.0% done\n",
      "48.0% done\n",
      "49.0% done\n",
      "50.0% done\n",
      "51.0% done\n",
      "52.0% done\n",
      "53.0% done\n",
      "54.0% done\n",
      "55.0% done\n",
      "56.0% done\n",
      "57.0% done\n",
      "58.0% done\n",
      "59.0% done\n",
      "60.0% done\n",
      "61.0% done\n",
      "62.0% done\n",
      "63.0% done\n",
      "64.0% done\n",
      "65.0% done\n",
      "66.0% done\n",
      "67.0% done\n",
      "68.0% done\n",
      "69.0% done\n",
      "70.0% done\n",
      "71.0% done\n",
      "72.0% done\n",
      "73.0% done\n",
      "74.0% done\n",
      "75.0% done\n",
      "76.0% done\n",
      "77.0% done\n",
      "78.0% done\n",
      "79.0% done\n",
      "80.0% done\n",
      "81.0% done\n",
      "82.0% done\n",
      "83.0% done\n",
      "84.0% done\n",
      "85.0% done\n",
      "86.0% done\n",
      "87.0% done\n",
      "88.0% done\n",
      "89.0% done\n",
      "90.0% done\n",
      "91.0% done\n",
      "92.0% done\n",
      "93.0% done\n",
      "94.0% done\n",
      "95.0% done\n",
      "96.0% done\n",
      "97.0% done\n",
      "98.0% done\n",
      "99.0% done\n",
      "calculating SVD ...\n",
      "\n",
      "[query] you\n",
      " i: 0.7173635363578796\n",
      " we: 0.6479985117912292\n",
      " always: 0.568203866481781\n",
      " anybody: 0.5483940243721008\n",
      " do: 0.5424485206604004\n",
      "\n",
      "[query] year\n",
      " month: 0.7099958062171936\n",
      " quarter: 0.6460947394371033\n",
      " earlier: 0.6203544735908508\n",
      " next: 0.6131435036659241\n",
      " last: 0.5903347134590149\n",
      "\n",
      "[query] car\n",
      " auto: 0.6174403429031372\n",
      " luxury: 0.5483920574188232\n",
      " domestic: 0.5251380801200867\n",
      " vehicle: 0.47324684262275696\n",
      " lexus: 0.4707452058792114\n",
      "\n",
      "[query] toyota\n",
      " motor: 0.6877408623695374\n",
      " nissan: 0.6635187864303589\n",
      " lexus: 0.5894770622253418\n",
      " mazda: 0.5830209851264954\n",
      " honda: 0.5646124482154846\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "wordvec_size = 100  # 100次元に削減\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "print('counting co-occurrence ...')\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('calculating PPMI ...')\n",
    "W = ppmi(C, verbose=True)\n",
    "\n",
    "print('calculating SVD ...')\n",
    "try:\n",
    "    from sklearn.utils.extmath import randomized_svd\n",
    "    U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5, random_state=None)\n",
    "    \n",
    "except ImportError:\n",
    "    U, S, V = np.linalg.svd(W)\n",
    "    \n",
    "word_vecs = U[:, :wordvec_size]\n",
    "\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73765d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
